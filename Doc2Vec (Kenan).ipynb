{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Doc2Vec (Kenan).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"75zwYdDl6L66","colab_type":"code","colab":{}},"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwt0LFcA6mm7","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import gensim\n","from gensim.utils import simple_preprocess\n","from gensim.parsing.preprocessing import STOPWORDS\n","from gensim.models.doc2vec import Doc2Vec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8R9ip2ar6pE3","colab_type":"code","colab":{}},"source":["downloaded = drive.CreateFile({'id':'1UDiOho3fJT_VRssVjn9ZI9SrBI34Fkh9'}) ## Load Secondary_Source.csv in the edge_list_creation folder\n","downloaded.GetContentFile('secondary_source.csv')  \n","file_dictionary = pd.read_csv('secondary_source.csv')\n","del file_dictionary['Unnamed: 0']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JghJU4v4Yvm1","colab_type":"code","outputId":"65c4e9e4-3744-49e5-a00f-ff1ba7e124aa","executionInfo":{"status":"ok","timestamp":1579544524854,"user_tz":480,"elapsed":1114,"user":{"displayName":"Kenan Jiang","photoUrl":"","userId":"02923904495947393073"}},"colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["file_dictionary"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Llop_2010_AuOr_28_Rec._OBO_160_5.txt</td>\n","      <td>Aula Orientalis 28, 2010, 139- 155 (ISSN: 0212...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>pardee2001b.txt</td>\n","      <td>Alphabet theofDevelopment and Origin The\\nIsra...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hecker_1978b_OrNS47_tib'imma.txt</td>\n","      <td>404\\ntibimma atalkim\\nAssyrerinnen im karumzei...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>pardee1979-80a.txt</td>\n","      <td>ey\\nIgnatios Ya‘qub 1918; II{, Liban Hissiyah,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Lassen, Agnete - Glyptic Encounters Appendicie...</td>\n","      <td>APPENDIX 3 APPENDIX 3: IDENTIFIED SEAL OWNERS\\...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1341</th>\n","      <td>Review of Brak.txt</td>\n","      <td>Excavationsat Tell Brak, Vol. 1: The Mitanni a...</td>\n","    </tr>\n","    <tr>\n","      <th>1342</th>\n","      <td>pru3pt1002.txt</td>\n","      <td>LE PALAIS DUGARIT 303\\nadopte pourfils, en pré...</td>\n","    </tr>\n","    <tr>\n","      <th>1343</th>\n","      <td>Ivanov_PIES2006.txt</td>\n","      <td>Proceedings of the 19th\\nAnnual UCLA Indo-Euro...</td>\n","    </tr>\n","    <tr>\n","      <th>1344</th>\n","      <td>McCreedy_2002_JNES63_Rev_Schloen_PHM.txt</td>\n","      <td>232 Journal of Near Eastern Studies Vol. 63 No...</td>\n","    </tr>\n","    <tr>\n","      <th>1345</th>\n","      <td>rowlandson.txt</td>\n","      <td>OXFORD CLASSICAL MONOGRAPHS\\nPublished under t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1346 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  Title                                            Content\n","0                  Llop_2010_AuOr_28_Rec._OBO_160_5.txt  Aula Orientalis 28, 2010, 139- 155 (ISSN: 0212...\n","1                                       pardee2001b.txt  Alphabet theofDevelopment and Origin The\\nIsra...\n","2                      Hecker_1978b_OrNS47_tib'imma.txt  404\\ntibimma atalkim\\nAssyrerinnen im karumzei...\n","3                                    pardee1979-80a.txt  ey\\nIgnatios Ya‘qub 1918; II{, Liban Hissiyah,...\n","4     Lassen, Agnete - Glyptic Encounters Appendicie...  APPENDIX 3 APPENDIX 3: IDENTIFIED SEAL OWNERS\\...\n","...                                                 ...                                                ...\n","1341                                 Review of Brak.txt  Excavationsat Tell Brak, Vol. 1: The Mitanni a...\n","1342                                     pru3pt1002.txt  LE PALAIS DUGARIT 303\\nadopte pourfils, en pré...\n","1343                                Ivanov_PIES2006.txt  Proceedings of the 19th\\nAnnual UCLA Indo-Euro...\n","1344           McCreedy_2002_JNES63_Rev_Schloen_PHM.txt  232 Journal of Near Eastern Studies Vol. 63 No...\n","1345                                     rowlandson.txt  OXFORD CLASSICAL MONOGRAPHS\\nPublished under t...\n","\n","[1346 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Acnv2SrT-4fj","colab_type":"code","colab":{}},"source":["file = file_dictionary.values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxWViPIqi7lV","colab_type":"code","outputId":"0ca8fb04-f6ef-473a-b608-df231f906293","executionInfo":{"status":"ok","timestamp":1579544528772,"user_tz":480,"elapsed":1339,"user":{"displayName":"Kenan Jiang","photoUrl":"","userId":"02923904495947393073"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import nltk\n","from nltk.corpus import stopwords\n","nltk.download(\"stopwords\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"BWSWNs0_i_QO","colab_type":"code","colab":{}},"source":["### Get the stopwords from different languages from nltk package\n","french_stopwords = stopwords.words('french')\n","german_stopwords = stopwords.words('german')\n","turkish_stopwords = stopwords.words('turkish')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7A3FZmBA8Dm","colab_type":"code","colab":{}},"source":["## This is a function designed to remove all the stopwords in our text\n","def preprocess(text): # one little problem, gensim.utils.simple_preprocess gets rid off \"I\" automatically. \n","    result = []\n","    for token in gensim.utils.simple_preprocess(text):\n","        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n","          if token not in french_stopwords:\n","            if token not in german_stopwords:\n","              if token not in turkish_stopwords:\n","                result.append(token)\n","    return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tr3TgiT7hWLJ","colab_type":"code","colab":{}},"source":["file_dictionary = {}\n","for i in file:\n","  file_dictionary[i[0]] = i[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XmSrFICA_kE","colab_type":"code","colab":{}},"source":["for key in file_dictionary:\n","  #print(\"working on file \"+ key)\n","  file_dictionary[key] = preprocess(file_dictionary[key])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxgY47MFZ8Rf","colab_type":"code","colab":{}},"source":["##this function tag all processed files so it is the form for Doc2Vec model \n","def tag_doc(processed, i):\n","  return gensim.models.doc2vec.TaggedDocument(processed, [str(i)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1B6DmRI-pSm1","colab_type":"code","colab":{}},"source":["temp_a = [(k,v) for k,v in file_dictionary.items()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"COzD8lgkX99i","colab_type":"code","colab":{}},"source":["temp = [i[1] for i in temp_a]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0eR9CyaHh7gt","colab_type":"code","colab":{}},"source":["processed_files = []\n","for i in range(len(temp)):\n","  processed_files.append(tag_doc(temp[i], i))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOpPAwgSWsf3","colab_type":"code","colab":{}},"source":["test_files = []\n","for i in range(len(temp)):\n","  test_files.append(temp[i])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aW2KE2j__EDi","colab_type":"code","colab":{}},"source":["model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=1, epochs=40)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJHllb1trbW_","colab_type":"code","colab":{}},"source":["model.build_vocab(processed_files)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tn61ozWWr9Jx","colab_type":"code","colab":{}},"source":["model.train(processed_files, total_examples=model.corpus_count, epochs=model.epochs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wc1Hx1xR9PpS","colab_type":"code","colab":{}},"source":["threshold = 0.9 #\n","Source = []\n","Target = []\n","Weight = []\n","number_of_doc = 500 ##change it 1346 for all"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RgPimf9qUYQ","colab_type":"code","colab":{}},"source":["for i in range(number_of_doc):\n","  for k in range(i+1, number_of_doc):\n","    print(\"working on \" + str(i) + \"comparing \"str(k))\n","    similar = model.n_similarity(test_files[i],test_files[k])\n","    if similar > threshold:\n","      Source.append(file[i][0])\n","      Target.append(file[k][0])\n","      Weight.append(similar) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjWchtUW-LUw","colab_type":"code","colab":{}},"source":["result = pd.DataFrame({'Source':Source, 'Target':Target, 'Similarity':Weight})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XEtV9pLTVgL","colab_type":"code","colab":{}},"source":["result"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CY_geNSN9-dn","colab_type":"text"},"source":["Important Note: To check each possible edge, there are around 500000 checks. Each check takes a second, it will cost us around 5 days to check all the edges."]},{"cell_type":"code","metadata":{"id":"oNfcXclQE8Fk","colab_type":"code","outputId":"c49f8ff0-8616-4dad-f1d6-c0354e9cc29d","executionInfo":{"status":"ok","timestamp":1579546433475,"user_tz":480,"elapsed":23280,"user":{"displayName":"Kenan Jiang","photoUrl":"","userId":"02923904495947393073"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fqebq2ZjE_jb","colab_type":"code","colab":{}},"source":["result.to_csv('Doc2Vec_edge_list.csv', index=False)\n","!cp Doc2Vec_edge_list.csv drive/My\\ Drive/AWCA/Collab_notebooks/edge_list_creation/"],"execution_count":0,"outputs":[]}]}